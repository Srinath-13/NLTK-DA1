{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSE 4022 Natural Language Processing - Digital Assignment 1\n",
    "#### ```Srinath NS 20BCE1074```\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1\n",
    "Utilize Python NLTK (Natural Language Tool Kit) Platform and do the following. \n",
    "Install relevant Packages and Libraries\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Explore Brown Corpus and find the size, tokens, categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Brown Corpus: 9964284\n",
      "Size of Brown Corpus in terms of words: 1161192\n"
     ]
    }
   ],
   "source": [
    "#Size of Brown Corpus\n",
    "size=len(brown.raw())\n",
    "print(\"Size of Brown Corpus:\", size)\n",
    "\n",
    "words=len(brown.words())\n",
    "print(\"Size of Brown Corpus in terms of words:\", words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Tokens (word) in Brown Corpus:  1439319\n",
      "Sample (10) word tokens:\n",
      "The/at, Fulton/np-tl, County/nn-tl, Grand/jj-tl, Jury/nn-tl, said/vbd, Friday/nr, an/at, investigation/nn, of/in, \n",
      "\n",
      "Number of Tokens (sentence) in Brown Corpus:  60647\n",
      "Sample (3) sentence tokens:\n",
      "\n",
      "\n",
      "\tThe/at Fulton/np-tl County/nn-tl Grand/jj-tl Jury/nn-tl said/vbd Friday/nr an/at investigation/nn of/in Atlanta's/np$ recent/jj primary/nn election/nn produced/vbd ``/`` no/at evidence/nn ''/'' that/cs any/dti irregularities/nns took/vbd place/nn ./.\n",
      "The/at jury/nn further/rbr said/vbd in/in term-end/nn presentments/nns that/cs the/at City/nn-tl Executive/jj-tl Committee/nn-tl ,/, which/wdt had/hvd over-all/jj charge/nn of/in the/at election/nn ,/, ``/`` deserves/vbz the/at praise/nn and/cc thanks/nns of/in the/at City/nn-tl of/in-tl Atlanta/np-tl ''/'' for/in the/at manner/nn in/in which/wdt the/at election/nn was/bedz conducted/vbn ./.\n",
      "The/at September-October/np term/nn jury/nn had/hvd been/ben charged/vbn by/in Fulton/np-tl Superior/jj-tl Court/nn-tl Judge/nn-tl Durwood/np Pye/np to/to investigate/vb reports/nns of/in possible/jj ``/`` irregularities/nns ''/'' in/in the/at hard-fought/jj primary/nn which/wdt was/bedz won/vbn by/in Mayor-nominate/nn-tl Ivan/np Allen/np Jr./np ./.\n"
     ]
    }
   ],
   "source": [
    "# Tokens in Brown Corpus\n",
    "tokens=nltk.word_tokenize(brown.raw())\n",
    "print(\"Number of Tokens (word) in Brown Corpus: \",len(tokens))\n",
    "print(\"Sample (10) word tokens:\")\n",
    "for t in tokens[:10]:\n",
    "    print(t,end=\", \")\n",
    "\n",
    "print(\"\\n\")\n",
    "s_tokens=nltk.sent_tokenize(brown.raw())\n",
    "print(\"Number of Tokens (sentence) in Brown Corpus: \",len(s_tokens))\n",
    "print(\"Sample (3) sentence tokens:\")\n",
    "for t in s_tokens[:3]:\n",
    "    print(t,end=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of categories in Brown Corpus:  15\n",
      "categories: ['adventure', 'belles_lettres', 'editorial', 'fiction', 'government', 'hobbies', 'humor', 'learned', 'lore', 'mystery', 'news', 'religion', 'reviews', 'romance', 'science_fiction']\n"
     ]
    }
   ],
   "source": [
    "#Categories in Brown Corpus\n",
    "categories=brown.categories()\n",
    "print(\"Number of categories in Brown Corpus: \",len(categories))\n",
    "print(\"categories:\",categories)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Find the size of word tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Brown Corpus in terms of words: 1161192\n",
      "Number of Tokens (word) in Brown Corpus:  1439319\n"
     ]
    }
   ],
   "source": [
    "words=len(brown.words())\n",
    "print(\"Size of Brown Corpus in terms of words:\", words)\n",
    "tokens=nltk.word_tokenize(brown.raw())\n",
    "print(\"Number of Tokens (word) in Brown Corpus: \",len(tokens))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Find the size of word types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of word types: 56057\n",
      "Size of tagged word types: 472\n"
     ]
    }
   ],
   "source": [
    "word_types=len(set(brown.words()))\n",
    "print(\"Size of word types:\", word_types)\n",
    "\n",
    "type_count=set()\n",
    "for i in brown.tagged_words():\n",
    "    type_count.add(i[1])\n",
    "\n",
    "print(\"Size of tagged word types:\", len(type_count))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Find the size of the category government"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the category 'government': 70117\n"
     ]
    }
   ],
   "source": [
    "government_words = len(brown.words(categories=['government']))\n",
    "print(\"Size of the category 'government':\", government_words)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Most Frequent tokens (10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Most frequent tokens: [('the', 62713), (',', 58334), ('.', 49346), ('of', 36080), ('and', 27915), ('to', 25732), ('a', 21881), ('in', 19536), ('that', 10237), ('is', 10011)]\n"
     ]
    }
   ],
   "source": [
    "fdist = nltk.FreqDist(brown.words())\n",
    "top_tokens = fdist.most_common(10)\n",
    "print(\"10 Most frequent tokens:\", top_tokens)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Count the number of sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences: 57340\n",
      "Number of Tokens (sentence) in Brown Corpus:  60647\n"
     ]
    }
   ],
   "source": [
    "sentences = len(brown.sents())\n",
    "print(\"Number of sentences:\", sentences)\n",
    "s_tokens=nltk.sent_tokenize(brown.raw())\n",
    "print(\"Number of Tokens (sentence) in Brown Corpus: \",len(s_tokens))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "Explore the corpora available in NLTK (any two): \n",
    "\n",
    "• ```Raw corpus``` \n",
    "• POS tagged \n",
    "• Parsed \n",
    "• Multilingual aligned\n",
    "• Spoken language\n",
    "• ```Semantic tagged```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Raw Corpus - WebText Corpus"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of raw content of webtext corpus: 1726164\n",
      "length of raw words of webtext corpus: 396733\n",
      "length of raw sentences of webtext corpus: 25733\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import webtext,gutenberg\n",
    "from nltk.tokenize import sent_tokenize,word_tokenize\n",
    "content=webtext.raw()\n",
    "print(\"length of raw content of webtext corpus:\", len(content))\n",
    "print(\"length of raw words of webtext corpus:\", len(webtext.words()))\n",
    "print(\"length of raw sentences of webtext corpus:\", len(webtext.sents()))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of word tokens of webtext corpus: 382576\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Cookie', 'Manager', ':', '``', 'Do', \"n't\", 'allow', 'sites', 'that', 'set']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words=word_tokenize(content)\n",
    "print(\"length of word tokens of webtext corpus:\", len(words))\n",
    "words[:10]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Stop Words Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of word tokens of webtext corpus after stop words removal: 284229\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words=set(stopwords.words(\"english\"))\n",
    "filtered_words=[w for w in words if not w in stop_words]\n",
    "print(\"length of word tokens of webtext corpus after stop words removal:\", len(filtered_words))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* POS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Cookie', 'NNP'),\n",
       " ('Manager', 'NNP'),\n",
       " (':', ':'),\n",
       " ('``', '``'),\n",
       " ('Do', 'VBP'),\n",
       " (\"n't\", 'RB'),\n",
       " ('allow', 'VB'),\n",
       " ('sites', 'NNS'),\n",
       " ('that', 'WDT'),\n",
       " ('set', 'VBP')]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_words=nltk.pos_tag(words)\n",
    "tagged_words[:10]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Number of Type of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of tagged word types: 45\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'#',\n",
       " '$',\n",
       " \"''\",\n",
       " '(',\n",
       " ')',\n",
       " ',',\n",
       " '.',\n",
       " ':',\n",
       " 'CC',\n",
       " 'CD',\n",
       " 'DT',\n",
       " 'EX',\n",
       " 'FW',\n",
       " 'IN',\n",
       " 'JJ',\n",
       " 'JJR',\n",
       " 'JJS',\n",
       " 'LS',\n",
       " 'MD',\n",
       " 'NN',\n",
       " 'NNP',\n",
       " 'NNPS',\n",
       " 'NNS',\n",
       " 'PDT',\n",
       " 'POS',\n",
       " 'PRP',\n",
       " 'PRP$',\n",
       " 'RB',\n",
       " 'RBR',\n",
       " 'RBS',\n",
       " 'RP',\n",
       " 'SYM',\n",
       " 'TO',\n",
       " 'UH',\n",
       " 'VB',\n",
       " 'VBD',\n",
       " 'VBG',\n",
       " 'VBN',\n",
       " 'VBP',\n",
       " 'VBZ',\n",
       " 'WDT',\n",
       " 'WP',\n",
       " 'WP$',\n",
       " 'WRB',\n",
       " '``'}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type_count=set()\n",
    "for i in tagged_words:\n",
    "    type_count.add(i[1])\n",
    "\n",
    "print(\"Size of tagged word types:\", len(type_count))\n",
    "type_count"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semantic Tagged Corpus - Wordnet Corpus\n",
    "* take words look synonyms, antonyms, definitions and context\n",
    "* Synset is a special kind of a simple interface that is present in NLTK to look up words in WordNet. Synset instances are the groupings of synonymous words that express the same concept. Some of the words have only one Synset and some have several."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Find the synsts present in the wordnet corpus, extract the words, definition of a particular word and give some examples.\n",
    "* Also for the word \"good\" find its antonyms and synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synsets:\n",
      " [Synset('plan.n.01'), Synset('program.n.02'), Synset('broadcast.n.02'), Synset('platform.n.02'), Synset('program.n.05'), Synset('course_of_study.n.01'), Synset('program.n.07'), Synset('program.n.08'), Synset('program.v.01'), Synset('program.v.02')]\n",
      "Just the word:\n",
      " plan\n",
      "Definition:\n",
      " a series of steps to be carried out or goals to be accomplished\n",
      "Examples:\n",
      " ['they drew up a six-step plan', 'they discussed plans for a new bond issue']\n",
      "Synonyms:\n",
      " {'trade_good', 'sound', 'skillful', 'just', 'effective', 'dear', 'safe', 'unspoiled', 'full', 'skilful', 'expert', 'commodity', 'respectable', 'proficient', 'practiced', 'in_effect', 'salutary', 'ripe', 'goodness', 'beneficial', 'estimable', 'good', 'in_force', 'near', 'well', 'unspoilt', 'secure', 'upright', 'thoroughly', 'dependable', 'right', 'honorable', 'adept', 'soundly', 'honest', 'undecomposed', 'serious'}\n",
      "Antonyms:\n",
      " {'bad', 'evilness', 'evil', 'ill', 'badness'}\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet\n",
    "syns=wordnet.synsets(\"program\")\n",
    "print(\"Synsets:\\n\",syns)\n",
    "print(\"Just the word:\\n\",syns[0].lemmas()[0].name())\n",
    "print(\"Definition:\\n\",syns[0].definition())\n",
    "print(\"Examples:\\n\",syns[0].examples())\n",
    "synonyms=[]\n",
    "antonyms=[]\n",
    "\n",
    "for syn in wordnet.synsets(\"good\"):\n",
    "    for l in syn.lemmas():\n",
    "        synonyms.append(l.name())\n",
    "        if l.antonyms():\n",
    "            antonyms.append(l.antonyms()[0].name())\n",
    "\n",
    "print(\"Synonyms:\\n\",set(synonyms))\n",
    "print(\"Antonyms:\\n\",set(antonyms))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semantic Similarity\n",
    "* Find the semantic similarity between two words of wordnet corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9090909090909091\n",
      "0.32\n"
     ]
    }
   ],
   "source": [
    "w1=wordnet.synset(\"ship.n.01\")\n",
    "w2=wordnet.synset(\"boat.n.01\")\n",
    "print(w1.wup_similarity(w2))\n",
    "\n",
    "w1=wordnet.synset(\"boat.n.01\")\n",
    "w2=wordnet.synset(\"human.n.01\")\n",
    "print(w1.wup_similarity(w2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "Create a text corpus with a minimum of 200 words (unique content). Implement the following text processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Srinath is a highly motivated and ambitious student currently studying at the Vellore Institute of Technology in Chennai, India. He is pursuing a degree in Computer Science with a specialization in Artificial Intelligence. Srinath has always been fascinated by the field of Natural Language Processing (NLP) and has made it his focus of study during his time at the institute. He has a strong background in computer science and programming, which has provided him with a solid foundation to build upon as he delves deeper into the intricacies of NLP. He has a keen interest in developing algorithms and models that can understand and generate natural language. Srinath has been actively involved in several research projects related to NLP during his time at the institute. He has been working on developing models for sentiment analysis, machine translation, and text summarization, among other things. He has also been working on creating a corpus of text data in multiple Indian languages, which can be used to train NLP models on various tasks. Srinath has been consistently achieving good grades in his classes and has been actively participating in various hackathons, coding competitions, and workshops. He has been awarded with prizes and recognition for his project related to NLP and AI. Srinath is also a team player and has been leading a team of students to work on a project related to NLP, where he has been mentoring them and providing guidance to them. He has been actively participating in various clubs and groups of the institute that are related to NLP and AI. Srinath is determined to make a career in NLP and is currently working on his final year project, which is related to NLP, where he is aiming to develop a model that can understand and generate natural language. He is looking forward to working in the industry and contribute to the field of NLP.\n"
     ]
    }
   ],
   "source": [
    "sentence=\"Srinath is a highly motivated and ambitious student currently studying at the Vellore Institute of Technology in Chennai, India. He is pursuing a degree in Computer Science with a specialization in Artificial Intelligence. Srinath has always been fascinated by the field of Natural Language Processing (NLP) and has made it his focus of study during his time at the institute. He has a strong background in computer science and programming, which has provided him with a solid foundation to build upon as he delves deeper into the intricacies of NLP. He has a keen interest in developing algorithms and models that can understand and generate natural language. Srinath has been actively involved in several research projects related to NLP during his time at the institute. He has been working on developing models for sentiment analysis, machine translation, and text summarization, among other things. He has also been working on creating a corpus of text data in multiple Indian languages, which can be used to train NLP models on various tasks. Srinath has been consistently achieving good grades in his classes and has been actively participating in various hackathons, coding competitions, and workshops. He has been awarded with prizes and recognition for his project related to NLP and AI. Srinath is also a team player and has been leading a team of students to work on a project related to NLP, where he has been mentoring them and providing guidance to them. He has been actively participating in various clubs and groups of the institute that are related to NLP and AI. Srinath is determined to make a career in NLP and is currently working on his final year project, which is related to NLP, where he is aiming to develop a model that can understand and generate natural language. He is looking forward to working in the industry and contribute to the field of NLP.\"\n",
    "print(sentence)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Word Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Words in the created text corpus :  342\n",
      "['Srinath', 'is', 'a', 'highly', 'motivated', 'and', 'ambitious', 'student', 'currently', 'studying', 'at', 'the', 'Vellore', 'Institute', 'of', 'Technology', 'in', 'Chennai', ',', 'India', '.', 'He', 'is', 'pursuing', 'a', 'degree', 'in', 'Computer', 'Science', 'with', 'a', 'specialization', 'in', 'Artificial', 'Intelligence', '.', 'Srinath', 'has', 'always', 'been', 'fascinated', 'by', 'the', 'field', 'of', 'Natural', 'Language', 'Processing', '(', 'NLP', ')', 'and', 'has', 'made', 'it', 'his', 'focus', 'of', 'study', 'during', 'his', 'time', 'at', 'the', 'institute', '.', 'He', 'has', 'a', 'strong', 'background', 'in', 'computer', 'science', 'and', 'programming', ',', 'which', 'has', 'provided', 'him', 'with', 'a', 'solid', 'foundation', 'to', 'build', 'upon', 'as', 'he', 'delves', 'deeper', 'into', 'the', 'intricacies', 'of', 'NLP', '.', 'He', 'has', 'a', 'keen', 'interest', 'in', 'developing', 'algorithms', 'and', 'models', 'that', 'can', 'understand', 'and', 'generate', 'natural', 'language', '.', 'Srinath', 'has', 'been', 'actively', 'involved', 'in', 'several', 'research', 'projects', 'related', 'to', 'NLP', 'during', 'his', 'time', 'at', 'the', 'institute', '.', 'He', 'has', 'been', 'working', 'on', 'developing', 'models', 'for', 'sentiment', 'analysis', ',', 'machine', 'translation', ',', 'and', 'text', 'summarization', ',', 'among', 'other', 'things', '.', 'He', 'has', 'also', 'been', 'working', 'on', 'creating', 'a', 'corpus', 'of', 'text', 'data', 'in', 'multiple', 'Indian', 'languages', ',', 'which', 'can', 'be', 'used', 'to', 'train', 'NLP', 'models', 'on', 'various', 'tasks', '.', 'Srinath', 'has', 'been', 'consistently', 'achieving', 'good', 'grades', 'in', 'his', 'classes', 'and', 'has', 'been', 'actively', 'participating', 'in', 'various', 'hackathons', ',', 'coding', 'competitions', ',', 'and', 'workshops', '.', 'He', 'has', 'been', 'awarded', 'with', 'prizes', 'and', 'recognition', 'for', 'his', 'project', 'related', 'to', 'NLP', 'and', 'AI', '.', 'Srinath', 'is', 'also', 'a', 'team', 'player', 'and', 'has', 'been', 'leading', 'a', 'team', 'of', 'students', 'to', 'work', 'on', 'a', 'project', 'related', 'to', 'NLP', ',', 'where', 'he', 'has', 'been', 'mentoring', 'them', 'and', 'providing', 'guidance', 'to', 'them', '.', 'He', 'has', 'been', 'actively', 'participating', 'in', 'various', 'clubs', 'and', 'groups', 'of', 'the', 'institute', 'that', 'are', 'related', 'to', 'NLP', 'and', 'AI', '.', 'Srinath', 'is', 'determined', 'to', 'make', 'a', 'career', 'in', 'NLP', 'and', 'is', 'currently', 'working', 'on', 'his', 'final', 'year', 'project', ',', 'which', 'is', 'related', 'to', 'NLP', ',', 'where', 'he', 'is', 'aiming', 'to', 'develop', 'a', 'model', 'that', 'can', 'understand', 'and', 'generate', 'natural', 'language', '.', 'He', 'is', 'looking', 'forward', 'to', 'working', 'in', 'the', 'industry', 'and', 'contribute', 'to', 'the', 'field', 'of', 'NLP', '.']\n"
     ]
    }
   ],
   "source": [
    "words = word_tokenize(sentence)\n",
    "print(\"Number of Words in the created text corpus : \",len(words))\n",
    "print(words)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Sentence Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Sentences :  14\n",
      "['Srinath is a highly motivated and ambitious student currently studying at the Vellore Institute of Technology in Chennai, India.', 'He is pursuing a degree in Computer Science with a specialization in Artificial Intelligence.', 'Srinath has always been fascinated by the field of Natural Language Processing (NLP) and has made it his focus of study during his time at the institute.', 'He has a strong background in computer science and programming, which has provided him with a solid foundation to build upon as he delves deeper into the intricacies of NLP.', 'He has a keen interest in developing algorithms and models that can understand and generate natural language.', 'Srinath has been actively involved in several research projects related to NLP during his time at the institute.', 'He has been working on developing models for sentiment analysis, machine translation, and text summarization, among other things.', 'He has also been working on creating a corpus of text data in multiple Indian languages, which can be used to train NLP models on various tasks.', 'Srinath has been consistently achieving good grades in his classes and has been actively participating in various hackathons, coding competitions, and workshops.', 'He has been awarded with prizes and recognition for his project related to NLP and AI.', 'Srinath is also a team player and has been leading a team of students to work on a project related to NLP, where he has been mentoring them and providing guidance to them.', 'He has been actively participating in various clubs and groups of the institute that are related to NLP and AI.', 'Srinath is determined to make a career in NLP and is currently working on his final year project, which is related to NLP, where he is aiming to develop a model that can understand and generate natural language.', 'He is looking forward to working in the industry and contribute to the field of NLP.']\n"
     ]
    }
   ],
   "source": [
    "sentences = sent_tokenize(sentence)\n",
    "print(\"Number of Sentences : \",len(sentences))\n",
    "print(sentences)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Convert to LowerCase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['srinath', 'is', 'a', 'highly', 'motivated', 'and', 'ambitious', 'student', 'currently', 'studying', 'at', 'the', 'vellore', 'institute', 'of', 'technology', 'in', 'chennai', ',', 'india', '.', 'he', 'is', 'pursuing', 'a', 'degree', 'in', 'computer', 'science', 'with', 'a', 'specialization', 'in', 'artificial', 'intelligence', '.', 'srinath', 'has', 'always', 'been', 'fascinated', 'by', 'the', 'field', 'of', 'natural', 'language', 'processing', '(', 'nlp', ')', 'and', 'has', 'made', 'it', 'his', 'focus', 'of', 'study', 'during', 'his', 'time', 'at', 'the', 'institute', '.', 'he', 'has', 'a', 'strong', 'background', 'in', 'computer', 'science', 'and', 'programming', ',', 'which', 'has', 'provided', 'him', 'with', 'a', 'solid', 'foundation', 'to', 'build', 'upon', 'as', 'he', 'delves', 'deeper', 'into', 'the', 'intricacies', 'of', 'nlp', '.', 'he', 'has', 'a', 'keen', 'interest', 'in', 'developing', 'algorithms', 'and', 'models', 'that', 'can', 'understand', 'and', 'generate', 'natural', 'language', '.', 'srinath', 'has', 'been', 'actively', 'involved', 'in', 'several', 'research', 'projects', 'related', 'to', 'nlp', 'during', 'his', 'time', 'at', 'the', 'institute', '.', 'he', 'has', 'been', 'working', 'on', 'developing', 'models', 'for', 'sentiment', 'analysis', ',', 'machine', 'translation', ',', 'and', 'text', 'summarization', ',', 'among', 'other', 'things', '.', 'he', 'has', 'also', 'been', 'working', 'on', 'creating', 'a', 'corpus', 'of', 'text', 'data', 'in', 'multiple', 'indian', 'languages', ',', 'which', 'can', 'be', 'used', 'to', 'train', 'nlp', 'models', 'on', 'various', 'tasks', '.', 'srinath', 'has', 'been', 'consistently', 'achieving', 'good', 'grades', 'in', 'his', 'classes', 'and', 'has', 'been', 'actively', 'participating', 'in', 'various', 'hackathons', ',', 'coding', 'competitions', ',', 'and', 'workshops', '.', 'he', 'has', 'been', 'awarded', 'with', 'prizes', 'and', 'recognition', 'for', 'his', 'project', 'related', 'to', 'nlp', 'and', 'ai', '.', 'srinath', 'is', 'also', 'a', 'team', 'player', 'and', 'has', 'been', 'leading', 'a', 'team', 'of', 'students', 'to', 'work', 'on', 'a', 'project', 'related', 'to', 'nlp', ',', 'where', 'he', 'has', 'been', 'mentoring', 'them', 'and', 'providing', 'guidance', 'to', 'them', '.', 'he', 'has', 'been', 'actively', 'participating', 'in', 'various', 'clubs', 'and', 'groups', 'of', 'the', 'institute', 'that', 'are', 'related', 'to', 'nlp', 'and', 'ai', '.', 'srinath', 'is', 'determined', 'to', 'make', 'a', 'career', 'in', 'nlp', 'and', 'is', 'currently', 'working', 'on', 'his', 'final', 'year', 'project', ',', 'which', 'is', 'related', 'to', 'nlp', ',', 'where', 'he', 'is', 'aiming', 'to', 'develop', 'a', 'model', 'that', 'can', 'understand', 'and', 'generate', 'natural', 'language', '.', 'he', 'is', 'looking', 'forward', 'to', 'working', 'in', 'the', 'industry', 'and', 'contribute', 'to', 'the', 'field', 'of', 'nlp', '.']\n"
     ]
    }
   ],
   "source": [
    "words = [word.lower() for word in words]\n",
    "print(words)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Stop Words Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Words left after stop words removal :  187\n",
      "['srinath', 'highly', 'motivated', 'ambitious', 'student', 'currently', 'studying', 'vellore', 'institute', 'technology', 'chennai', ',', 'india', '.', 'pursuing', 'degree', 'computer', 'science', 'specialization', 'artificial', 'intelligence', '.', 'srinath', 'always', 'fascinated', 'field', 'natural', 'language', 'processing', '(', 'nlp', ')', 'made', 'focus', 'study', 'time', 'institute', '.', 'strong', 'background', 'computer', 'science', 'programming', ',', 'provided', 'solid', 'foundation', 'build', 'upon', 'delves', 'deeper', 'intricacies', 'nlp', '.', 'keen', 'interest', 'developing', 'algorithms', 'models', 'understand', 'generate', 'natural', 'language', '.', 'srinath', 'actively', 'involved', 'several', 'research', 'projects', 'related', 'nlp', 'time', 'institute', '.', 'working', 'developing', 'models', 'sentiment', 'analysis', ',', 'machine', 'translation', ',', 'text', 'summarization', ',', 'among', 'things', '.', 'also', 'working', 'creating', 'corpus', 'text', 'data', 'multiple', 'indian', 'languages', ',', 'used', 'train', 'nlp', 'models', 'various', 'tasks', '.', 'srinath', 'consistently', 'achieving', 'good', 'grades', 'classes', 'actively', 'participating', 'various', 'hackathons', ',', 'coding', 'competitions', ',', 'workshops', '.', 'awarded', 'prizes', 'recognition', 'project', 'related', 'nlp', 'ai', '.', 'srinath', 'also', 'team', 'player', 'leading', 'team', 'students', 'work', 'project', 'related', 'nlp', ',', 'mentoring', 'providing', 'guidance', '.', 'actively', 'participating', 'various', 'clubs', 'groups', 'institute', 'related', 'nlp', 'ai', '.', 'srinath', 'determined', 'make', 'career', 'nlp', 'currently', 'working', 'final', 'year', 'project', ',', 'related', 'nlp', ',', 'aiming', 'develop', 'model', 'understand', 'generate', 'natural', 'language', '.', 'looking', 'forward', 'working', 'industry', 'contribute', 'field', 'nlp', '.']\n"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))\n",
    "words = [word for word in words if word not in stop_words]\n",
    "print(\"Number of Words left after stop words removal : \", len(words))\n",
    "print(words)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['srinath', 'highli', 'motiv', 'ambiti', 'student', 'current', 'studi', 'vellor', 'institut', 'technolog', 'chennai', ',', 'india', '.', 'pursu', 'degre', 'comput', 'scienc', 'special', 'artifici', 'intellig', '.', 'srinath', 'alway', 'fascin', 'field', 'natur', 'languag', 'process', '(', 'nlp', ')', 'made', 'focu', 'studi', 'time', 'institut', '.', 'strong', 'background', 'comput', 'scienc', 'program', ',', 'provid', 'solid', 'foundat', 'build', 'upon', 'delv', 'deeper', 'intricaci', 'nlp', '.', 'keen', 'interest', 'develop', 'algorithm', 'model', 'understand', 'gener', 'natur', 'languag', '.', 'srinath', 'activ', 'involv', 'sever', 'research', 'project', 'relat', 'nlp', 'time', 'institut', '.', 'work', 'develop', 'model', 'sentiment', 'analysi', ',', 'machin', 'translat', ',', 'text', 'summar', ',', 'among', 'thing', '.', 'also', 'work', 'creat', 'corpu', 'text', 'data', 'multipl', 'indian', 'languag', ',', 'use', 'train', 'nlp', 'model', 'variou', 'task', '.', 'srinath', 'consist', 'achiev', 'good', 'grade', 'class', 'activ', 'particip', 'variou', 'hackathon', ',', 'code', 'competit', ',', 'workshop', '.', 'award', 'prize', 'recognit', 'project', 'relat', 'nlp', 'ai', '.', 'srinath', 'also', 'team', 'player', 'lead', 'team', 'student', 'work', 'project', 'relat', 'nlp', ',', 'mentor', 'provid', 'guidanc', '.', 'activ', 'particip', 'variou', 'club', 'group', 'institut', 'relat', 'nlp', 'ai', '.', 'srinath', 'determin', 'make', 'career', 'nlp', 'current', 'work', 'final', 'year', 'project', ',', 'relat', 'nlp', ',', 'aim', 'develop', 'model', 'understand', 'gener', 'natur', 'languag', '.', 'look', 'forward', 'work', 'industri', 'contribut', 'field', 'nlp', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "stemmed_words = [stemmer.stem(word) for word in words]\n",
    "\n",
    "print(stemmed_words)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "srinath, highly, motivated, ambitious, student, currently, studying, vellore, institute, technology, chennai, ,, india, ., pursuing, degree, computer, science, specialization, artificial, intelligence, ., srinath, always, fascinated, field, natural, language, processing, (, nlp, ), made, focus, study, time, institute, ., strong, background, computer, science, programming, ,, provided, solid, foundation, build, upon, delf, deeper, intricacy, nlp, ., keen, interest, developing, algorithm, model, understand, generate, natural, language, ., srinath, actively, involved, several, research, project, related, nlp, time, institute, ., working, developing, model, sentiment, analysis, ,, machine, translation, ,, text, summarization, ,, among, thing, ., also, working, creating, corpus, text, data, multiple, indian, language, ,, used, train, nlp, model, various, task, ., srinath, consistently, achieving, good, grade, class, actively, participating, various, hackathons, ,, coding, competition, ,, workshop, ., awarded, prize, recognition, project, related, nlp, ai, ., srinath, also, team, player, leading, team, student, work, project, related, nlp, ,, mentoring, providing, guidance, ., actively, participating, various, club, group, institute, related, nlp, ai, ., srinath, determined, make, career, nlp, currently, working, final, year, project, ,, related, nlp, ,, aiming, develop, model, understand, generate, natural, language, ., looking, forward, working, industry, contribute, field, nlp, ., "
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "for i in lemmatized_words:\n",
    "    print(i,end=\", \")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Part of Speech Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('srinath', 'NN'), ('highly', 'RB'), ('motivated', 'VBD'), ('ambitious', 'JJ'), ('student', 'NN'), ('currently', 'RB'), ('studying', 'VBG'), ('vellore', 'IN'), ('institute', 'JJ'), ('technology', 'NN'), ('chennai', 'NN'), (',', ','), ('india', 'NN'), ('.', '.'), ('pursuing', 'VBG'), ('degree', 'JJ'), ('computer', 'NN'), ('science', 'NN'), ('specialization', 'NN'), ('artificial', 'JJ'), ('intelligence', 'NN'), ('.', '.'), ('srinath', 'NN'), ('always', 'RB'), ('fascinated', 'VBD'), ('field', 'NN'), ('natural', 'JJ'), ('language', 'NN'), ('processing', 'NN'), ('(', '('), ('nlp', 'NN'), (')', ')'), ('made', 'VBD'), ('focus', 'NN'), ('study', 'NN'), ('time', 'NN'), ('institute', 'NN'), ('.', '.'), ('strong', 'JJ'), ('background', 'NN'), ('computer', 'NN'), ('science', 'NN'), ('programming', 'NN'), (',', ','), ('provided', 'VBD'), ('solid', 'JJ'), ('foundation', 'NN'), ('build', 'VB'), ('upon', 'IN'), ('delves', 'NNS'), ('deeper', 'JJR'), ('intricacies', 'NNS'), ('nlp', 'VBP'), ('.', '.'), ('keen', 'JJ'), ('interest', 'NN'), ('developing', 'VBG'), ('algorithms', 'JJ'), ('models', 'NNS'), ('understand', 'VBP'), ('generate', 'JJ'), ('natural', 'JJ'), ('language', 'NN'), ('.', '.'), ('srinath', 'NN'), ('actively', 'RB'), ('involved', 'JJ'), ('several', 'JJ'), ('research', 'NN'), ('projects', 'NNS'), ('related', 'VBN'), ('nlp', 'JJ'), ('time', 'NN'), ('institute', 'NN'), ('.', '.'), ('working', 'VBG'), ('developing', 'VBG'), ('models', 'NNS'), ('sentiment', 'NN'), ('analysis', 'NN'), (',', ','), ('machine', 'NN'), ('translation', 'NN'), (',', ','), ('text', 'JJ'), ('summarization', 'NN'), (',', ','), ('among', 'IN'), ('things', 'NNS'), ('.', '.'), ('also', 'RB'), ('working', 'VBG'), ('creating', 'VBG'), ('corpus', 'JJ'), ('text', 'NN'), ('data', 'NNS'), ('multiple', 'JJ'), ('indian', 'JJ'), ('languages', 'NNS'), (',', ','), ('used', 'VBD'), ('train', 'NN'), ('nlp', 'JJ'), ('models', 'NNS'), ('various', 'JJ'), ('tasks', 'NNS'), ('.', '.'), ('srinath', 'NN'), ('consistently', 'RB'), ('achieving', 'VBG'), ('good', 'JJ'), ('grades', 'NNS'), ('classes', 'NNS'), ('actively', 'RB'), ('participating', 'VBG'), ('various', 'JJ'), ('hackathons', 'NNS'), (',', ','), ('coding', 'VBG'), ('competitions', 'NNS'), (',', ','), ('workshops', 'NNS'), ('.', '.'), ('awarded', 'VBD'), ('prizes', 'JJ'), ('recognition', 'NN'), ('project', 'NN'), ('related', 'VBN'), ('nlp', 'JJ'), ('ai', 'NN'), ('.', '.'), ('srinath', 'NN'), ('also', 'RB'), ('team', 'NN'), ('player', 'NN'), ('leading', 'VBG'), ('team', 'NN'), ('students', 'NNS'), ('work', 'VBP'), ('project', 'NN'), ('related', 'VBN'), ('nlp', 'RB'), (',', ','), ('mentoring', 'VBG'), ('providing', 'VBG'), ('guidance', 'NN'), ('.', '.'), ('actively', 'RB'), ('participating', 'VBG'), ('various', 'JJ'), ('clubs', 'NNS'), ('groups', 'NNS'), ('institute', 'VBP'), ('related', 'VBN'), ('nlp', 'JJ'), ('ai', 'NN'), ('.', '.'), ('srinath', 'NN'), ('determined', 'VBD'), ('make', 'VBP'), ('career', 'NN'), ('nlp', 'NNS'), ('currently', 'RB'), ('working', 'VBG'), ('final', 'JJ'), ('year', 'NN'), ('project', 'NN'), (',', ','), ('related', 'JJ'), ('nlp', 'NN'), (',', ','), ('aiming', 'VBG'), ('develop', 'VB'), ('model', 'NN'), ('understand', 'NN'), ('generate', 'VB'), ('natural', 'JJ'), ('language', 'NN'), ('.', '.'), ('looking', 'VBG'), ('forward', 'RB'), ('working', 'VBG'), ('industry', 'NN'), ('contribute', 'JJ'), ('field', 'NN'), ('nlp', 'NN'), ('.', '.'), "
     ]
    }
   ],
   "source": [
    "\n",
    "pos_tagged_words = nltk.pos_tag(words)\n",
    "for i in pos_tagged_words:\n",
    "    print(i,end=\", \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2469a70536e4d2335a2ea8907942d0699c37342a371ac185bdb5b0aa6f073890"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
